{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\r\n"
     ]
    }
   ],
   "source": [
    "# For Mac Users\n",
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Splinter to visit the NASA website\n",
    "url= 'https://mars.nasa.gov/news/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most current article on NASA.gov is \"AI Is Helping Scientists Discover Fresh Craters on Mars.\"\n",
      "The article, \"AI Is Helping Scientists Discover Fresh Craters on Mars,\" is about It's the first time machine learning has been used to find previously unknown craters on the Red Planet.\n"
     ]
    }
   ],
   "source": [
    "# Create HTML object   \n",
    "html=browser.html\n",
    "\n",
    "# Create BeautifulSoup object to parse using html.parser\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Use classes to extract information\n",
    "news_title = soup.find('div', class_='list_text').find('div', class_='content_title').text\n",
    "print(f'The most current article on NASA.gov is \"{news_title}.\"')\n",
    "\n",
    "# Extract the teaser paragraph for the first article\n",
    "news_p = soup.find('div', class_='article_teaser_body').text\n",
    "print(f'The article, \"{news_title},\" is about {news_p}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit URL\n",
    "url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and click the full image button\n",
    "full_image_elem = browser.find_by_id('full_image')\n",
    "full_image_elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the more info button and click that\n",
    "browser.is_element_present_by_text('more info', wait_time=1)\n",
    "more_info_elem = browser.links.find_by_partial_text('more info')\n",
    "more_info_elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the resulting html with soup\n",
    "html = browser.html\n",
    "img_soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/spaceimages/images/largesize/PIA18884_hires.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the relative image url\n",
    "img_url_rel = img_soup.select_one('figure.lede a img').get(\"src\")\n",
    "img_url_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA18884_hires.jpg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the base url to create an absolute url\n",
    "img_url = f'https://www.jpl.nasa.gov{img_url_rel}'\n",
    "img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Splinter to visit the space images website\n",
    "featured_url = 'https://www.jpl.nasa.gov/spaceimages'\n",
    "browser.visit(featured_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3a8d480e183d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Identify all using parent figure....\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlink\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Print link\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "# Create HTML object\n",
    "image_html = browser.html\n",
    "\n",
    "# Create BeautifulSoup object to parse using html.parser\n",
    "soup = bs(image_html, 'html.parser')\n",
    "\n",
    "# Use Splinter to click on 'full image' button\n",
    "featured_image_link = browser.find_by_id(\"full_image\")\n",
    "featured_image_link.click()\n",
    "\n",
    "# Allow execution to be suspended for 2 seconds\n",
    "time.sleep(2)\n",
    "full_image= browser.links.find_by_partial_text('more info')\n",
    "full_image.click()\n",
    "\n",
    "# Identify all using parent figure....\n",
    "link= soup.find('figure').find('a').get('href')\n",
    "\n",
    "# Print link \n",
    "# Combine original url with image url to create image link\n",
    "landing_url= 'https://www.jpl.nasa.gov'\n",
    "featured_image_url= landing_url + link\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Identify link for space facts scrape\n",
    "facts_url= \"htpps://space-facts.com/mars/\"\n",
    "\n",
    "# Read in webpage from url\n",
    "tables= pd.read_html(facts_url)\n",
    "\n",
    "# Print table from website using tables[0]\n",
    "mars_info_df=tables[0]\n",
    "\n",
    "# Change column headers \n",
    "mars_info_df.columns= [\"Description\", \"Value\"]\n",
    "\n",
    "# Save table to files folder\n",
    "mars_facts_table=mars_info_df.to_html(\"mars_facts_table.html\")\n",
    "mars_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use splinter to link to space images url\n",
    "hemisphere_url= 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(hemisphere_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_html= browser.html\n",
    "soup= bs(image_html, 'html.parser')\n",
    "hemispheres= soup.find_all('div', class_='item')\n",
    "hemisphere_urls= []\n",
    "main_link= 'https://astrogeology.usgs.gov'\n",
    "\n",
    "# Get the title of each image\n",
    "for h in hemispheres:\n",
    "    title= h.find('h3').text.strip('Enhanced')\n",
    "# Pull links for images \n",
    "    end_link= h.find('a').get(\"href\")\n",
    "# Combine main and end links for the new browser\n",
    "browser.visit(main_link + end_link)\n",
    "# HTML object for images\n",
    "images_html= browser.html\n",
    "# Parse HTML with Beautiful Soup for every individual hemishphere information website\n",
    "soup= bs(images_html, 'html.parser')\n",
    "# Pull link for full image \n",
    "img_url = main_link + soup.find('img', class_='wide-image').get('src')\n",
    "# Append the retreived information into a list of dictionaries \n",
    "hemisphere_urls.append({\"title\": title, \"img_url\": img_url})\n",
    "hemisphere_urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
